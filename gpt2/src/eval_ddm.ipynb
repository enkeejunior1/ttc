{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import argparse\n",
    "import os\n",
    "import tqdm\n",
    "import inspect\n",
    "import logging\n",
    "\n",
    "from models.teacher import Teacher\n",
    "from models.configuration_teacher import TeacherConfig\n",
    "from data import CoTDataset, CoTDataCollator, extract_answer\n",
    "\n",
    "from utils import get_sep_position\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_pretrained_model(args):\n",
    "    if args.base_model == \"sedd\":\n",
    "        # load model\n",
    "        from ddms.sedd import SEDD\n",
    "        model = SEDD.from_pretrained(\"louaaron/sedd-small\")\n",
    "\n",
    "        # load config\n",
    "        args.num_vocabs = model.config.tokens\n",
    "        args.length = model.config.model.length\n",
    "        args.noise_schedule = model.config.noise.type\n",
    "        args.graph = 'absorb'\n",
    "    \n",
    "    if args.base_model == \"mdlm\":\n",
    "        model = AutoModelForMaskedLM.from_pretrained(\"kuleshov-group/mdlm-owt\", trust_remote_code=True)\n",
    "        \n",
    "        # load config\n",
    "        args.num_vocabs = model.config.vocab_size - 1\n",
    "        args.length = model.config.model_length\n",
    "        args.noise_schedule = 'loglinear'\n",
    "        args.graph = 'absorb'\n",
    "    \n",
    "    return model, args\n",
    "\n",
    "def load_diffusion_scheduler(args):\n",
    "    if args.base_model == \"sedd\":\n",
    "        pass\n",
    "    if args.base_model == \"mdlm\":\n",
    "        from ddms import mdlm\n",
    "        if args.scheduler_name == \"euler\":\n",
    "            scheduler = mdlm.EulerScheduler(args)\n",
    "        if args.scheduler_name == \"maskgit\":\n",
    "            scheduler = mdlm.MaskGITScheduler(args)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    test_path = \"../data/gsm8k/test.txt\"\n",
    "    model_path = \"../train_models/gsm8k/mdlm/teacher/checkpoint_0/model.safetensors\"\n",
    "    max_new_tokens = 1024\n",
    "    batch_size = 1\n",
    "    base_model = 'mdlm'\n",
    "    scheduler_name = 'maskgit'\n",
    "    num_inf = 16\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 float32 cuda 0\n",
      "Creating features from dataset file at ../data/gsm8k/test.txt\n",
      "tgt_avg:  27.708870356330554\n",
      "src_avg:  57.5352539802881\n",
      "ratios:  2.076420050344752\n",
      "tgt_avg:  6.0962850644427595\n",
      "src_avg:  57.5352539802881\n",
      "ratios:  9.437756497948017\n",
      " Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? <|endoftext|> <<16-3-4=9>> <<9*2=18>> <|endoftext|> #### 18 <|endoftext|>\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 9959, 1433, 12, 18, 12, 19, 28, 24, 4211, 9959, 24, 9, 17, 28, 1507, 4211, 220, 50256]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1303, 21017, 1248, 220, 50256]\n",
      "[28111, 447, 247, 82, 39694, 3830, 1467, 9653, 583, 1110, 13, 1375, 25365, 1115, 329, 12607, 790, 3329, 290, 275, 1124, 27563, 1040, 329, 607, 2460, 790, 1110, 351, 1440, 13, 1375, 16015, 262, 17675, 379, 262, 9818, 6, 1910, 4445, 329, 720, 17, 583, 4713, 22045, 5935, 13, 1374, 881, 287, 5054, 857, 673, 787, 790, 1110, 379, 262, 9818, 6, 1910, 30, 220, 50256, 1303, 21017, 1248, 220, 50256]\n",
      " Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? <|endoftext|> #### 18 <|endoftext|>\n",
      "[28111, 447, 247, 82, 39694, 3830, 1467, 9653, 583, 1110, 13, 1375, 25365, 1115, 329, 12607, 790, 3329, 290, 275, 1124, 27563, 1040, 329, 607, 2460, 790, 1110, 351, 1440, 13, 1375, 16015, 262, 17675, 379, 262, 9818, 6, 1910, 4445, 329, 720, 17, 583, 4713, 22045, 5935, 13, 1374, 881, 287, 5054, 857, 673, 787, 790, 1110, 379, 262, 9818, 6, 1910, 30, 220]\n",
      "[50256, 1303, 21017, 1248, 220, 50256]\n"
     ]
    }
   ],
   "source": [
    "dtype = 'float32'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ctx = torch.amp.autocast(device_type='cuda', dtype=ptdtype)\n",
    "print(ptdtype, dtype, device, torch.cuda.current_device()\n",
    ")\n",
    "\n",
    "# Load finetuned model \n",
    "teacher, args = load_pretrained_model(args)\n",
    "teacher.load_state_dict(load_file(args.model_path))\n",
    "scheduler = load_diffusion_scheduler(args)\n",
    "teacher = teacher.to(device, ptdtype)\n",
    "\n",
    "# Load data\n",
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "collate_fn = CoTDataCollator(tokenizer)\n",
    "test_dataset = CoTDataset(tokenizer, args.test_path, 1024)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1319 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    dataloader, tokenizer, ctx, teacher, scheduler, num_inf, loss_fn\n",
    ") = (\n",
    "    test_dataloader, tokenizer, ctx, teacher, scheduler, args.num_inf, None\n",
    ")\n",
    "teacher.eval()\n",
    "total_instances = 0\n",
    "total_tokens = 0\n",
    "total_correct = 0\n",
    "total_correct_tokens = 0\n",
    "total_loss = 0\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    break\n",
    "\n",
    "# Remove answer part\n",
    "sep_positions = get_sep_position(input_ids_all, tokenizer.eos_token_id)\n",
    "input_ids = input_ids_all\n",
    "input_ids[:, sep_positions.max():] = scheduler.mask_idx\n",
    "batch_size = input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "# gen_output = scheduler.euler_sample(\n",
    "#     teacher, xt=input_ids, \n",
    "#     t=1, s=1e-5, num_inference_steps=num_inf\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonghyun/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:397: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
      "/home/yonghyun/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/yonghyun/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"b s (three h d) -> b s three h d\".\n Input tensor shape: torch.Size([1, 77, 77, 2304]). Additional info: {'three': 3, 'h': 12}.\n Wrong shape: expected 3 dims. Received 4-dim tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/einops/einops.py:522\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    521\u001b[0m shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mshape(tensor)\n\u001b[0;32m--> 522\u001b[0m recipe \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_transformation_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_recipe(\n\u001b[1;32m    524\u001b[0m     backend, recipe, cast(Tensor, tensor), reduction_type\u001b[38;5;241m=\u001b[39mreduction, axes_lengths\u001b[38;5;241m=\u001b[39mhashable_axes_lengths\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/einops/einops.py:365\u001b[0m, in \u001b[0;36m_prepare_transformation_recipe\u001b[0;34m(pattern, operation, axes_names, ndim)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcomposition):\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong shape: expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcomposition)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dims. Received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-dim tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    366\u001b[0m left_composition \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mcomposition\n",
      "\u001b[0;31mEinopsError\u001b[0m: Wrong shape: expected 3 dims. Received 4-dim tensor.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m dk \u001b[38;5;241m=\u001b[39m k[i] \u001b[38;5;241m-\u001b[39m k[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m sigma_bar_t \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39msigma_bar(k[\u001b[38;5;28;01mNone\u001b[39;00m, i])\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_bar_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mstep(output, xt, dk)\n\u001b[1;32m     18\u001b[0m xt \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mxt\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:436\u001b[0m, in \u001b[0;36mMDLM.forward\u001b[0;34m(self, input_ids, timesteps, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    427\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    428\u001b[0m   output_hidden_states\n\u001b[1;32m    429\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    430\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    431\u001b[0m )\n\u001b[1;32m    432\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \\\n\u001b[1;32m    433\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \\\n\u001b[1;32m    434\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 436\u001b[0m logits, all_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m  \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m  \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m  \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[1;32m    442\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m modeling_outputs\u001b[38;5;241m.\u001b[39mMaskedLMOutput(\n\u001b[1;32m    443\u001b[0m     logits\u001b[38;5;241m=\u001b[39mlogits,\n\u001b[1;32m    444\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mall_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    445\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    446\u001b[0m   )\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:399\u001b[0m, in \u001b[0;36mDITBackbone.forward\u001b[0;34m(self, indices, sigma, output_hidden_states)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16):\n\u001b[1;32m    398\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)):\n\u001b[0;32m--> 399\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_cos_sin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    402\u001b[0m       all_hidden_states\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/kuleshov-group/mdlm-owt/9e6829bb908d241a074146e4c5c095238bb5e316/modeling_mdlm.py:281\u001b[0m, in \u001b[0;36mDDiTBlock.forward\u001b[0;34m(self, x, rotary_cos_sin, c, seqlens)\u001b[0m\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m modulate_fused(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), shift_msa, scale_msa)\n\u001b[1;32m    280\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_qkv(x)\n\u001b[0;32m--> 281\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb s (three h d) -> b s three h d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                \u001b[49m\u001b[43mthree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m                \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    286\u001b[0m   cos, sin \u001b[38;5;241m=\u001b[39m rotary_cos_sin\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/einops/einops.py:591\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    537\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/einops/einops.py:533\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"b s (three h d) -> b s three h d\".\n Input tensor shape: torch.Size([1, 77, 77, 2304]). Additional info: {'three': 3, 'h': 12}.\n Wrong shape: expected 3 dims. Received 4-dim tensor."
     ]
    }
   ],
   "source": [
    "model=teacher\n",
    "xt=input_ids\n",
    "num_inference_steps=num_inf\n",
    "\n",
    "length = (xt == scheduler.mask_idx).sum(dim=1)\n",
    "\n",
    "eps = 1e-3\n",
    "t = torch.linspace(1, eps, num_inference_steps + 1, device=xt.device)\n",
    "k = (1 - (-scheduler.sigma_bar(t)).exp()) * length\n",
    "k = k.long()\n",
    "k[-1] = 0\n",
    "\n",
    "for i in range(num_inference_steps):\n",
    "    dk = k[i] - k[i+1]\n",
    "    sigma_bar_t = scheduler.sigma_bar(k[None, i])\n",
    "    output = model(xt, torch.zeros_like(sigma_bar_t))\n",
    "    output = scheduler.step(output, xt, dk)\n",
    "    xt = output.xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = 3\n",
    "\n",
    "def sample_categorical(categorical_probs, eps=1e-6, generator=None):\n",
    "    '''use gumbel-max trick, but given probability'''\n",
    "    if generator is None:\n",
    "        gumbel_noise = torch.rand_like(categorical_probs)\n",
    "    else:\n",
    "        gumbel_noise = torch.rand(categorical_probs.shape, generator=generator, device=generator.device).to(categorical_probs)\n",
    "    gumbel_noise = (eps - torch.log(eps + (1 - eps) * gumbel_noise))\n",
    "    return torch.argmax(categorical_probs / gumbel_noise, dim=-1), gumbel_noise\n",
    "\n",
    "# generate x0 ~ p_x0\n",
    "logits = scheduler.output_to_logits(output, xt)\n",
    "p_x0 = logits.exp()\n",
    "x0, noise = sample_categorical(p_x0)\n",
    "\n",
    "# mask x0 w.r.t confidence \n",
    "conf = torch.gather(p_x0, -1, x0[..., None])\n",
    "conf[xt != scheduler.mask_idx] = -torch.inf\n",
    "conf_v, _ = torch.topk(conf, dk, dim=1)\n",
    "mask = (conf >= conf_v.min(dim=1, keepdim=True).values.squeeze(-1)).to(xt)\n",
    "xs = mask * xt + (1 - mask) * x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  943,  2188,   468,  ...,   284, 14958, 50256],\n",
       "         [  943,  2188,   468,  ...,   284, 14958, 50256],\n",
       "         [  943,  2188,   468,  ...,   284, 14958, 50256],\n",
       "         ...,\n",
       "         [  943,  2188,   468,  ...,   284, 14958, 50256],\n",
       "         [  943,  2188,   468,  ..., 50257, 50257, 50257],\n",
       "         [  943,  2188,   468,  ..., 50257, 50257, 50257]]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0928]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<MinBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "torch.topk(conf.squeeze(), dk, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate x0 ~ p_x0\n",
    "logits = scheduler.output_to_logits(output, xt)\n",
    "p_x0 = logits.exp()\n",
    "x0, noise = sample_categorical(p_x0)\n",
    "\n",
    "# mask x0 w.r.t confidence \n",
    "conf = torch.gather(p_x0, -1, x0[..., None])\n",
    "conf[xt != scheduler.mask_idx] = -torch.inf\n",
    "conf_v, _ = torch.topk(conf, dk, dim=1)\n",
    "mask = (conf - torch.min(conf_v, dim=1, keepdim=True).values).to(xt.dtype)\n",
    "xs = mask * xt + (1 - mask) * x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=teacher\n",
    "xt=input_ids\n",
    "t=1. * torch.ones(batch_size, device=xt.device)\n",
    "s=1e-5 * torch.ones(batch_size, device=xt.device)\n",
    "num_inference_steps=num_inf\n",
    "\n",
    "timesteps = torch.linspace(1, scheduler.eps, num_inference_steps+1, device=xt.device)\n",
    "timesteps = (t[:, None] - s[:, None]) * timesteps[None, :] + s[:, None]\n",
    "for i in range(num_inference_steps):\n",
    "    dt = timesteps[:, i] - timesteps[:, i+1]\n",
    "    curr_t = timesteps[:, i]\n",
    "\n",
    "    sigma_bar_t = scheduler.sigma_bar(curr_t)\n",
    "    output = model(xt, torch.zeros_like(sigma_bar_t))\n",
    "    output = scheduler.step(output, xt, curr_t, dt)\n",
    "    xt = output.xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(xt[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_ids[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gen_output = scheduler.generate(\n",
    "#     input_ids=input_ids,\n",
    "#     num_inf=num_inf,\n",
    "# )\n",
    "# Evaluate\n",
    "#import pdb; pdb.set_trace()\n",
    "for i, (input_ids_all_i, gen_output_i) in enumerate(zip(input_ids_all, gen_output)):\n",
    "    sep_position = sep_positions[i].item()\n",
    "    tgt = input_ids_all_i[sep_position+1:]\n",
    "    tgt_text = tokenizer.decode(tgt, skip_special_tokens=True)\n",
    "    ans = extract_answer(tgt_text)\n",
    "    pred_text = tokenizer.decode(gen_output_i[0][sep_position+1:], skip_special_tokens=True)\n",
    "    pred_ans = extract_answer(pred_text)\n",
    "    if ans == pred_ans:\n",
    "        total_correct += 1\n",
    "    if i == 0:\n",
    "        print(f'Input: {tokenizer.decode(input_ids_all_i[:sep_position], skip_special_tokens=True)}')\n",
    "        print(f'Target: {tgt_text}')\n",
    "        print(f'Predicted: {pred_text}')\n",
    "        print('')\n",
    "accuracy = total_correct / total_instances\n",
    "token_accuracy = total_correct_tokens / total_tokens\n",
    "loss = total_loss / total_tokens\n",
    "ppl = math.exp(loss)\n",
    "return accuracy, token_accuracy, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    # Remove answer part\n",
    "    sep_positions = get_sep_position(input_ids_all, tokenizer.eos_token_id)\n",
    "    input_ids = input_ids_all\n",
    "    input_ids[:, :sep_positions.max()+1] = scheduler.mask_idx\n",
    "    batch_size = input_ids.shape[0]\n",
    "    if loss_fn:\n",
    "        with ctx:\n",
    "            outputs = loss_fn(input_ids=input_ids_all, labels=labels)\n",
    "        total_loss += outputs.total_loss.item()\n",
    "        total_correct_tokens += outputs.total_correct.item()\n",
    "        total_tokens += outputs.total_tokens\n",
    "        total_instances += batch_size\n",
    "\n",
    "    # Generate\n",
    "    gen_output = scheduler.euler_sample(\n",
    "        teacher, xt=input_ids, \n",
    "        t=1, s=1e-5, num_inference_steps=num_inf\n",
    "    )\n",
    "    # gen_output = scheduler.generate(\n",
    "    #     input_ids=input_ids,\n",
    "    #     num_inf=num_inf,\n",
    "    # )\n",
    "    # Evaluate\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for i, (input_ids_all_i, gen_output_i) in enumerate(zip(input_ids_all, gen_output)):\n",
    "        sep_position = sep_positions[i].item()\n",
    "        tgt = input_ids_all_i[sep_position+1:]\n",
    "        tgt_text = tokenizer.decode(tgt, skip_special_tokens=True)\n",
    "        ans = extract_answer(tgt_text)\n",
    "        pred_text = tokenizer.decode(gen_output_i[0][sep_position+1:], skip_special_tokens=True)\n",
    "        pred_ans = extract_answer(pred_text)\n",
    "        if ans == pred_ans:\n",
    "            total_correct += 1\n",
    "        if i == 0:\n",
    "            print(f'Input: {tokenizer.decode(input_ids_all_i[:sep_position], skip_special_tokens=True)}')\n",
    "            print(f'Target: {tgt_text}')\n",
    "            print(f'Predicted: {pred_text}')\n",
    "            print('')\n",
    "accuracy = total_correct / total_instances\n",
    "token_accuracy = total_correct_tokens / total_tokens\n",
    "loss = total_loss / total_tokens\n",
    "ppl = math.exp(loss)\n",
    "return accuracy, token_accuracy, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ctx = torch.amp.autocast(device_type='cuda', dtype=ptdtype)\n",
    "print (ptdtype, dtype, device)\n",
    "\n",
    "# Create Teacher \n",
    "teacher, args = load_pretrained_model(args)\n",
    "scheduler = load_diffusion_scheduler(args)\n",
    "\n",
    "# Load data\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "collate_fn = CoTDataCollator(tokenizer)\n",
    "train_dataset = CoTDataset(tokenizer, args.train_path, 1024)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "val_dataset = CoTDataset(tokenizer, args.val_path, 1024)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm.tqdm(train_dataloader):\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.rand(4,4)\n",
    "xt = torch.zeros(4,4)\n",
    "cond = x0 > 0.5\n",
    "xt[cond] = x0[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(batch['input_ids_only'][1].tolist()))\n",
    "print(tokenizer.decode([220]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,4,5,6)\n",
    "x[x > 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(batch['input_ids_only'][0].tolist()))\n",
    "print(tokenizer.decode(batch['input_ids_only'][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['input_ids_only'].shape)\n",
    "print(batch['input_ids_cot'].shape)\n",
    "print(batch['input_ids_nocot'].shape)\n",
    "print(batch['input_ids_all'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids_only'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids_all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm.tqdm(val_dataloader):\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
