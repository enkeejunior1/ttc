{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# See the `MDLM` collection page on the hub for list of available models.\n",
    "model_name = 'kuleshov-group/mdlm-owt'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, GPT2TokenizerFast\n",
    "import argparse\n",
    "import os\n",
    "import tqdm\n",
    "import inspect\n",
    "import logging\n",
    "\n",
    "from models.teacher import Teacher\n",
    "from models.configuration_teacher import TeacherConfig\n",
    "from data import CoTDataset, CoTDataCollator, extract_answer\n",
    "\n",
    "from utils import get_sep_position\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    train_path = '../data/gsm8k/train.txt'\n",
    "    val_path = '../data/gsm8k/valid.txt'\n",
    "    save_model = 'train_models/gsm8k/mdlm/teacher'\n",
    "    max_new_tokens = 128\n",
    "    base_model = 'mdlm'\n",
    "    epochs = 1\n",
    "    batch_size = 32\n",
    "    lr = 5e-5\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(args):\n",
    "    if args.base_model == \"sedd\":\n",
    "        # load model\n",
    "        from ddms.sedd import SEDD\n",
    "        model = SEDD.from_pretrained(\"louaaron/sedd-small\")\n",
    "\n",
    "        # load config\n",
    "        args.num_vocabs = model.config.tokens\n",
    "        args.length = model.config.model.length\n",
    "        args.noise_schedule = model.config.noise.type\n",
    "        args.graph = 'absorb'\n",
    "    \n",
    "    if args.base_model == \"mdlm\":\n",
    "        model = AutoModelForMaskedLM.from_pretrained(\"kuleshov-group/mdlm-owt\", trust_remote_code=True)\n",
    "        \n",
    "        # load config\n",
    "        args.num_vocabs = model.config.vocab_size\n",
    "        args.length = model.config.model_length\n",
    "        args.noise_schedule = 'loglinear'\n",
    "        args.graph = 'absorb'\n",
    "    \n",
    "    return model, args\n",
    "\n",
    "def load_diffusion_scheduler(args):\n",
    "    if args.base_model == \"sedd\":\n",
    "        from ddms import sedd\n",
    "        scheduler = sedd.EulerScheduler(args)\n",
    "    if args.base_model == \"mdlm\":\n",
    "        from ddms import mdlm\n",
    "        scheduler = mdlm.EulerScheduler(args)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ctx = torch.amp.autocast(device_type='cuda', dtype=ptdtype)\n",
    "print (ptdtype, dtype, device)\n",
    "\n",
    "# Create Teacher \n",
    "teacher, args = load_pretrained_model(args)\n",
    "scheduler = load_diffusion_scheduler(args)\n",
    "\n",
    "# Load data\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "collate_fn = CoTDataCollator(tokenizer)\n",
    "train_dataset = CoTDataset(tokenizer, args.train_path, 1024)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "val_dataset = CoTDataset(tokenizer, args.val_path, 1024)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12020 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm.tqdm(train_dataloader):\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.rand(4,4)\n",
    "xt = torch.zeros(4,4)\n",
    "cond = x0 > 0.5\n",
    "xt[cond] = x0[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A lion needs to gain 500 pounds for the winter. In the summer, it feasts on zebras and during autumn, it hunts gazelles and buffalos. It gained half its weight from zebras during summer and during autumn, it gained a quarter of that amount from gazelles. Buffalos made up the rest of its diet. How many pounds did it gain eating buffalos? <|endoftext|> \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(batch['input_ids_only'][1].tolist()))\n",
    "print(tokenizer.decode([220]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,4,5,6)\n",
    "x[x > 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1002, 27775, 13267,  ..., 50256, 50256, 50256],\n",
       "        [  317, 18744,  2476,  ...,   220, 50256,   220],\n",
       "        [ 8114,   468,   642,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [ 3362,  6593, 19132,  ..., 50256, 50256, 50256],\n",
       "        [25737,  6134,  3126,  ..., 50256, 50256, 50256],\n",
       "        [ 1629,   257,  3807,  ..., 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If Kanye decides to jog around the park for 3 hours and a bottle of water is 500ml and costs $0.5. He drinks 1 bottle after each hour to stay hydrated, how much does he spend on water in total? <|endoftext|> <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      " A lion needs to gain 500 pounds for the winter. In the summer, it feasts on zebras and during autumn, it hunts gazelles and buffalos. It gained half its weight from zebras during summer and during autumn, it gained a quarter of that amount from gazelles. Buffalos made up the rest of its diet. How many pounds did it gain eating buffalos? <|endoftext|> \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(batch['input_ids_only'][0].tolist()))\n",
    "print(tokenizer.decode(batch['input_ids_only'][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['input_ids_only'].shape)\n",
    "print(batch['input_ids_cot'].shape)\n",
    "print(batch['input_ids_nocot'].shape)\n",
    "print(batch['input_ids_all'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids_only'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids_all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm.tqdm(val_dataloader):\n",
    "    input_ids_all = batch['input_ids_all'].to(device)\n",
    "    labels = batch['labels_all'].to(device)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
