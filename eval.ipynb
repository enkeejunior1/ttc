{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, GPT2TokenizerFast\n",
    "import argparse\n",
    "import os\n",
    "import tqdm\n",
    "import inspect\n",
    "import logging\n",
    "\n",
    "from models.teacher import Teacher\n",
    "from models.configuration_teacher import TeacherConfig\n",
    "from data import CoTDataset, CoTDataCollator, extract_answer\n",
    "\n",
    "from utils import get_sep_position\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    train_path = 'data/gsm8k/train.txt'\n",
    "    val_path = 'data/gsm8k/valid.txt'\n",
    "    save_model = 'train_models/gsm8k/mdlm/teacher'\n",
    "    max_new_tokens = 128\n",
    "    base_model = 'sedd'\n",
    "    epochs = 1\n",
    "    batch_size = 32\n",
    "    lr = 5e-5\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AdamW\n",
    "import argparse\n",
    "import os\n",
    "import inspect\n",
    "import tqdm\n",
    "import logging\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.data import CoTDataset, CoTDataCollator, extract_answer\n",
    "from src.models.emulator import Emulator\n",
    "from src.models.student import Student\n",
    "from src.utils import get_sep_position\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--test_path', type=str, required=True)\n",
    "# parser.add_argument('--batch_size', type=int, default=1)\n",
    "# parser.add_argument('--max_new_tokens', type=int, default=128)\n",
    "# parser.add_argument('--student_path', type=str, required=True)\n",
    "# parser.add_argument('--emulator_path', type=str, required=True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "bsz = 1\n",
    "student_path = \"models/4_by_4_mult/gpt2/student\"\n",
    "emulator_path = \"models/4_by_4_mult/gpt2/emulator\"\n",
    "\n",
    "class Args:\n",
    "    test_path = \"data/4_by_4_mult/test_bigbench.txt\"\n",
    "    batch_size = bsz\n",
    "    max_new_tokens = 128\n",
    "    student_path = student_path\n",
    "    emulator_path = emulator_path\n",
    "\n",
    "args = Args()\n",
    "print(args)\n",
    "\n",
    "dtype = 'float32'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ctx = torch.amp.autocast(device_type='cuda', dtype=ptdtype)\n",
    "print(ptdtype, dtype, device)\n",
    "\n",
    "# Load Models\n",
    "emulator = Emulator.from_pretrained(args.emulator_path).to(device).to(ptdtype)\n",
    "student = Student.from_pretrained(args.student_path).to(device).to(ptdtype)\n",
    "emulator.eval()\n",
    "student.eval()\n",
    "\n",
    "# Load data\n",
    "tokenizer = emulator.tokenizer\n",
    "collate_fn = CoTDataCollator(tokenizer)\n",
    "test_dataset = CoTDataset(tokenizer, args.test_path, 1024)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "accuracy, throughput  = evaluate(test_dataloader, tokenizer, ctx, emulator, student, args.max_new_tokens)\n",
    "print(f\"Test Accuracy: {accuracy}. Throughput: {throughput}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(dataloader, tokenizer, ctx, emulator, student, max_new_tokens):\n",
    "    total_time = 0\n",
    "    total_instances = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        input_ids_all = batch['input_ids_nocot'].to(device)\n",
    "        # Remove answer part\n",
    "        sep_positions = get_sep_position(input_ids_all, tokenizer.eos_token_id)\n",
    "        input_ids = input_ids_all[:, :sep_positions.max()+1]\n",
    "        start_time = time.time()\n",
    "        with ctx:\n",
    "            emulated_teacher_states = emulator(input_ids)\n",
    "\n",
    "            # Generate from student\n",
    "            beam_output = student.generate(\n",
    "                input_ids=input_ids,\n",
    "                teacher_states=emulated_teacher_states,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "            )\n",
    "\n",
    "        # Evaluate\n",
    "        #import pdb; pdb.set_trace()\n",
    "        for i, (input_ids_all_i, beam_output_i) in enumerate(zip(input_ids_all, beam_output)):\n",
    "            #sep_position = input_ids_single.tolist().index(tokenizer.eos_token_id)\n",
    "            sep_position = sep_positions[i].item()\n",
    "            tgt = input_ids_all_i[sep_position+1:]\n",
    "            tgt_text = tokenizer.decode(tgt, skip_special_tokens=True)\n",
    "            ans = extract_answer(tgt_text)\n",
    "            pred_text = tokenizer.decode(beam_output_i[0][sep_position+1:], skip_special_tokens=True)\n",
    "            pred_ans = extract_answer(pred_text)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            total_instances += 1\n",
    "            if ans == pred_ans:\n",
    "                total_correct += 1\n",
    "        end_time = time.time()\n",
    "        total_time += end_time - start_time\n",
    "\n",
    "    #print (total_time, total_instances, total_instances / total_time)\n",
    "    throughput = total_instances / total_time\n",
    "    accuracy = total_correct / total_instances\n",
    "    return accuracy, throughput\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test_path', type=str, required=True)\n",
    "    parser.add_argument('--batch_size', type=int, default=1)\n",
    "    parser.add_argument('--max_new_tokens', type=int, default=128)\n",
    "    parser.add_argument('--student_path', type=str, required=True)\n",
    "    parser.add_argument('--emulator_path', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print (args)\n",
    "    \n",
    "    dtype = 'float32'\n",
    "    ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ctx = torch.amp.autocast(device_type='cuda', dtype=ptdtype)\n",
    "    print (ptdtype, dtype, device)\n",
    "\n",
    "\n",
    "    # Load Models\n",
    "    emulator = Emulator.from_pretrained(args.emulator_path).to(device).to(ptdtype)\n",
    "    student = Student.from_pretrained(args.student_path).to(device).to(ptdtype)\n",
    "    emulator.eval()\n",
    "    student.eval()\n",
    "\n",
    "    # Load data\n",
    "    tokenizer = emulator.tokenizer\n",
    "    collate_fn = CoTDataCollator(tokenizer)\n",
    "    test_dataset = CoTDataset(tokenizer, args.test_path, 1024)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "    accuracy, throughput  = evaluate(test_dataloader, tokenizer, ctx, emulator, student, args.max_new_tokens)\n",
    "    print (f\"Test Accuracy: {accuracy}. Throughput: {throughput}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation (N by N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_n_by_n(order):\n",
    "    # Randomly sample two numbers\n",
    "    multiplicand = random.randint(10**(order-1), 10**order)  # Adjust the range as needed\n",
    "    multiplier = random.randint(10**(order-1), 10**order)    # Adjust the range as needed\n",
    "\n",
    "    # Compute the product\n",
    "    product = multiplicand * multiplier\n",
    "\n",
    "    # Extract digits of the multiplier in reverse order\n",
    "    multiplier_digits = [int(d) for d in str(multiplier)][::-1]\n",
    "\n",
    "    partial_products = []\n",
    "    cumulative_sum = 0\n",
    "    cumulative_sums = []\n",
    "\n",
    "    for i, digit in enumerate(multiplier_digits):\n",
    "        # partial_product for display\n",
    "        partial_product = multiplicand * digit * 10**i\n",
    "        partial_product_rev = str(partial_product)[::-1]\n",
    "        partial_product_rev = partial_product_rev + '0' * max(0, order+1+i-len(partial_product_rev))\n",
    "        partial_products.append(partial_product_rev)\n",
    "\n",
    "        # Update cumulative sum\n",
    "        cumulative_sum += partial_product\n",
    "\n",
    "        # Reverse cumulative sum for display\n",
    "        cumulative_sum_rev = str(cumulative_sum)[::-1]\n",
    "        cumulative_sum_rev = cumulative_sum_rev + '0' * max(0, order+1+i-len(cumulative_sum_rev))\n",
    "        cumulative_sums.append(cumulative_sum_rev)\n",
    "\n",
    "    # Format the chain of thought\n",
    "    cot_str = [' '.join(list(partial_products[0]))]\n",
    "    for pp, cs in zip(partial_products[1:-1], cumulative_sums[1:-1]):\n",
    "        pp_str = ' '.join([' '.join(list(pp)), '( ' + ' '.join(list(cs)) + ' )'])\n",
    "        cot_str.append(pp_str)\n",
    "    cot_str.append(' '.join(list(partial_products[-1])))\n",
    "    cot_str = ' + '.join(cot_str)\n",
    "\n",
    "    # Format the dataset\n",
    "    multiplicand_rev = str(multiplicand)[::-1]\n",
    "    multiplier_rev = str(multiplier)[::-1]\n",
    "    q_str = ' * '.join([' '.join(list(multiplicand_rev)), ' '.join(list(multiplier_rev))])\n",
    "    a_str = ' '.join(list(cumulative_sums[-1]))\n",
    "    all_str = f\"{q_str}||{cot_str} #### {a_str}\"\n",
    "    \n",
    "    return all_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Generate 808k training examples and 1k validation examples\n",
    "num_train = 808 * 1e3 # 1e3\n",
    "num_valid = 1 * 1e3 # 1e3\n",
    "num_test = 1 * 1e3 # 1e3\n",
    "\n",
    "for order in [7, 8, 9, 10]:\n",
    "    data_dir = f'data/{order}_by_{order}_mult'\n",
    "\n",
    "    train_set = set()\n",
    "    valid_set = set()\n",
    "    test_set = set()\n",
    "\n",
    "    # Generate training data\n",
    "    while len(train_set) < num_train:\n",
    "        example = generate_n_by_n(order)\n",
    "        equation = example.split('\\n')[0]  # Use the first line as a unique identifier\n",
    "        if equation not in train_set:\n",
    "            train_set.add(example)\n",
    "\n",
    "    # Generate validation data\n",
    "    while len(valid_set) < num_valid:\n",
    "        example = generate_n_by_n(order)\n",
    "        equation = example.split('\\n')[0]\n",
    "        if equation not in train_set and equation not in valid_set:\n",
    "            valid_set.add(example)\n",
    "\n",
    "    # Generate test data\n",
    "    while len(test_set) < num_test:\n",
    "        example = generate_n_by_n(order)\n",
    "        equation = example.split('\\n')[0]\n",
    "        if equation not in train_set and equation not in valid_set and equation not in test_set:\n",
    "            test_set.add(example)\n",
    "\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Write training data to a file\n",
    "    with open(f'{data_dir}/train.txt', 'w') as f:\n",
    "        for example in train_set:\n",
    "            f.write(example + '\\n')\n",
    "\n",
    "    # Write validation data to a file\n",
    "    with open(f'{data_dir}/valid.txt', 'w') as f:\n",
    "        for example in valid_set:\n",
    "            f.write(example + '\\n')\n",
    "\n",
    "    # Write test data to a file\n",
    "    with open(f'{data_dir}/test_bigbench.txt', 'w') as f:\n",
    "        for example in test_set:\n",
    "            f.write(example + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
