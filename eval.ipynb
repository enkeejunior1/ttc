{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import fire\n",
    "import mup\n",
    "import lib.datasets\n",
    "from lib.datasets import get_dataloaders\n",
    "import lib.models\n",
    "import lib.utils\n",
    "import os\n",
    "import torch\n",
    "import logging, sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # args (experiments)\n",
    "    \"runs\": 1,              # 1\n",
    "    \"fix_src\": True,        # fix context \n",
    "    \"cot\": False,           # False # thought-level diffusion, q+previous cot -> next thought\n",
    "    \"cot_steps\": None,      # 12\n",
    "    \"digit\": True,          # Use Digits pre_tokenizer\n",
    "    \"limit\": True,          # Debug (< 5 instances)\n",
    "\n",
    "    # args (datasets)\n",
    "    \"dataset\": \"4by4\",      # 4by4, 5by5, gsm8k, boolean\n",
    "    \"seq_len\": 256,         # \"boolean\": 384, \"else\": 256\n",
    "    \"vocab_size\": 1024,     # follow pretrained LM\n",
    "    \"model_name\": \"gpt\",    # gpt, sedd, mdlm\n",
    "    \"model_size\": \"small\",  # small, medium\n",
    "    \n",
    "    # args (model)\n",
    "    \"dim\": 2048,            # 2048\n",
    "    \"n_blocks\": 24,         # 24\n",
    "    \"n_heads\": 32,          # 32\n",
    "    \"embed_dim\": 16,        # 16\n",
    "    \n",
    "    # args (train)\n",
    "    \"batch_size\": 168,      # 168\n",
    "\n",
    "    # args (diffusion)\n",
    "    \"sampling_timesteps\": 64, # 64\n",
    "\n",
    "    # args (sampling)\n",
    "    \"logit_sample\": False,  # False\n",
    "    \"logit_temp\": 0.5,      # 0.5\n",
    "    \n",
    "    # args (noise schedule - only for palid?)\n",
    "    \"gamma_0\": -3,          # -3.\n",
    "    \"gamma_1\": 6.,          # 6.\n",
    "    # \"initial_noise_scale\": None, # 1.0\n",
    "    # \"dpm_solver\": None,   # False\n",
    "    \"score_temp\": 0.5,      # 0.5\n",
    "\n",
    "    # args (???)\n",
    "    \"apply_sc\": False,    # \"True\": acc / \"False\": mean \n",
    "}\n",
    "args = OmegaConf.create(args)\n",
    "args.weights_path = f\"{args.model_name}-{args.model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_log_name = f\"eval-{args.sampling_timesteps}-score_{args.score_temp}\"\n",
    "if args.apply_sc:\n",
    "    eval_log_name += f'-sc'\n",
    "if args.logit_sample:\n",
    "    eval_log_name += f'-logit-{args.logit_temp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_log = os.path.join(args.weights_path, f\"{eval_log_name}.log\")\n",
    "if lib.ddp.rank() == 0:\n",
    "    if os.path.exists(args.eval_log): \n",
    "        os.remove(args.eval_log)\n",
    "\n",
    "targets = logging.StreamHandler(sys.stdout), logging.FileHandler(args.eval_log, mode='w')\n",
    "logging.basicConfig(format='[%(asctime)s] %(message)s', level=logging.INFO, handlers=targets)\n",
    "# lib.utils.print_args(args)\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "def create_modules(dim, n_heads):\n",
    "    return {\n",
    "        'noise_schedule': lib.models.NoiseSchedule().float(),\n",
    "        'gamma_bounds': lib.models.GammaBounds(args.gamma_0, args.gamma_1).float(),\n",
    "        'embedding_matrix': lib.models.EmbeddingMatrix(args.vocab_size, args.embed_dim).float(),\n",
    "        'model': lib.models.DiffusionModel(dim, args.embed_dim, args.n_blocks, n_heads, args.vocab_size).float()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fused_layer_norm_cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m base_modules \u001b[38;5;241m=\u001b[39m create_modules(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m delta_modules \u001b[38;5;241m=\u001b[39m create_modules(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mcreate_modules\u001b[0;34m(dim, n_heads)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_modules\u001b[39m(dim, n_heads):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: lib\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mNoiseSchedule()\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma_bounds\u001b[39m\u001b[38;5;124m'\u001b[39m: lib\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mGammaBounds(args\u001b[38;5;241m.\u001b[39mgamma_0, args\u001b[38;5;241m.\u001b[39mgamma_1)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: lib\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mEmbeddingMatrix(args\u001b[38;5;241m.\u001b[39mvocab_size, args\u001b[38;5;241m.\u001b[39membed_dim)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiffusionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     20\u001b[0m     }\n",
      "File \u001b[0;32m/data/yonghyun/ttc/lib/models.py:192\u001b[0m, in \u001b[0;36mDiffusionModel.__init__\u001b[0;34m(self, dim, embed_dim, n_blocks, n_heads, vocab_size)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mrotary\u001b[38;5;241m.\u001b[39mRotary(dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_heads)\n\u001b[1;32m    191\u001b[0m residual_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(n_blocks))\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    193\u001b[0m     TransformerBlock(dim, n_heads, \u001b[38;5;28;01mFalse\u001b[39;00m, residual_scale)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_blocks)\n\u001b[1;32m    195\u001b[0m ])\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_norm \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mLayerNorm(dim)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear \u001b[38;5;241m=\u001b[39m mup\u001b[38;5;241m.\u001b[39mMuReadout(dim, vocab_size)\n",
      "File \u001b[0;32m/data/yonghyun/ttc/lib/models.py:193\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mrotary\u001b[38;5;241m.\u001b[39mRotary(dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_heads)\n\u001b[1;32m    191\u001b[0m residual_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(n_blocks))\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 193\u001b[0m     \u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_blocks)\n\u001b[1;32m    195\u001b[0m ])\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_norm \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mLayerNorm(dim)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear \u001b[38;5;241m=\u001b[39m mup\u001b[38;5;241m.\u001b[39mMuReadout(dim, vocab_size)\n",
      "File \u001b[0;32m/data/yonghyun/ttc/lib/models.py:68\u001b[0m, in \u001b[0;36mTransformerBlock.__init__\u001b[0;34m(self, dim, n_heads, causal, residual_scale)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m=\u001b[39m n_heads\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_scale \u001b[38;5;241m=\u001b[39m residual_scale\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrmsnorm1 \u001b[38;5;241m=\u001b[39m \u001b[43mapex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFusedRMSNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_qkv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(dim, \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mdim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(dim, dim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/data/yonghyun/anaconda3/envs/ttc/lib/python3.10/site-packages/apex/normalization/fused_layer_norm.py:393\u001b[0m, in \u001b[0;36mFusedRMSNorm.__init__\u001b[0;34m(self, normalized_shape, eps, elementwise_affine, memory_efficient)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m fused_layer_norm_cuda\n\u001b[0;32m--> 393\u001b[0m fused_layer_norm_cuda \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused_layer_norm_cuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(normalized_shape, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m    396\u001b[0m     normalized_shape \u001b[38;5;241m=\u001b[39m (normalized_shape,)\n",
      "File \u001b[0;32m/data/yonghyun/anaconda3/envs/ttc/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fused_layer_norm_cuda'"
     ]
    }
   ],
   "source": [
    "modules = create_modules(args.dim, args.n_heads)\n",
    "base_modules = create_modules(256, 4)\n",
    "delta_modules = create_modules(128, 2)\n",
    "for key in modules:\n",
    "    main, base, delta = modules[key], base_modules[key], delta_modules[key]\n",
    "    mup.set_base_shapes(main, base, delta=delta)\n",
    "    main.cuda()\n",
    "\n",
    "logging.info(f'Loading weights from {args.weights_path}')\n",
    "for name, module in modules.items():\n",
    "    module.load_state_dict(torch.load(\n",
    "        os.path.join(args.weights_path, f'{name}.pt'),\n",
    "        map_location=torch.device('cuda')\n",
    "    ))\n",
    "\n",
    "for key in modules:\n",
    "    logging.info(key+':')\n",
    "    lib.utils.print_model(modules[key])\n",
    "\n",
    "(test_loader,), (word2idx, idx2word), tokenizer = get_dataloaders(\n",
    "    args.dataset, args.batch_size, args.seq_len, args.cot, args.digit, only_test=True\n",
    ")\n",
    "\n",
    "# evaluate(\n",
    "#     args, \n",
    "#     test_loader, \n",
    "#     tokenizer, \n",
    "#     modules, \n",
    "#     log_interval=True, \n",
    "#     runs=args.runs,\n",
    "#     apply_sc=args.apply_sc\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddms.sedd import SEDD\n",
    "\n",
    "# load model\n",
    "model = SEDD.from_pretrained(args.weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
